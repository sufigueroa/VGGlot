{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Librerías"
      ],
      "metadata": {
        "id": "nJRpJLm-6OxT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6RaYAlH49o7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.io\n",
        "import random\n",
        "from PIL import Image\n",
        "from copy import copy, deepcopy\n",
        "from IPython.display import display\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from os import listdir\n",
        "from os.path import join\n",
        "from tqdm.notebook import tqdm\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, Resize\n",
        "from torchvision.models import ResNeXt101_64X4D_Weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jaUw4MU6Tnj",
        "outputId": "afc3a641-9a9e-4c26-fd78-7f1f65d8b072"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset"
      ],
      "metadata": {
        "id": "K5CiZOpD7Mhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "repo_url = 'https://github.com/brendenlake/omniglot.git'\n",
        "subprocess.call(['git', 'clone', repo_url])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkLlB9uc673h",
        "outputId": "67fc5bad-49cc-4ef9-8b9d-a50130ac51fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq './omniglot/python/images_background.zip'\n",
        "!unzip -qq './omniglot/python/strokes_background.zip'"
      ],
      "metadata": {
        "id": "pWL6GcIE7Qpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Orden de las imágenes"
      ],
      "metadata": {
        "id": "a_MT-bf69Bh9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la carpeta images_background, hay 30 alfabetos diferentes. Cada alfabeto contiene una cantidad variada de caracteres, entre 20-50 aprox. Cada uno de los caracteres cuenta es de la forma XXXX_YY.png, donde XXXX corresponde al identificador del caracter, el cual es único entre todos los caracteres de todos los alfabetos. YY corresponde al número de muestra de un caracter en específico, el cual va siempre desde 01 hasta 20 (20 muestras por caracter)."
      ],
      "metadata": {
        "id": "QxmwZVpv-VH_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora bien, el problema está en que los XXXX no vienen ordenados secuencialmente en cada uno de los alfabetos. Por lo tanto, para hacer el preprocesamiento, hará un diccionario que mapeará cada uno de los id a un valor ordenado, para que la posterior clasificación sea más rápida."
      ],
      "metadata": {
        "id": "PEwVNtlt_xs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_dir = 'images_background'\n",
        "# stroke_dir = 'strokes_background'\n",
        "nreps = 20 # number of renditions for each character\n",
        "# nalpha = 5 # number of alphabets to show\n",
        "\n",
        "alphabet_names = sorted([a for a in os.listdir(img_dir) if a[0] != '.']) # get folder names\n",
        "length_alphabet_names = len(alphabet_names)\n",
        "character_lengths = [len(os.listdir(os.path.join(img_dir, alph_name))) for alph_name in alphabet_names]\n",
        "\n",
        "# alphabet_names = random.sample(alphabet_names,nalpha) # choose random alphabets\n",
        "# print(len(alphabet_names))\n",
        "\n",
        "N = sum([len(os.listdir(os.path.join(img_dir, alph_name, char)))\n",
        "            for alph_name in alphabet_names\n",
        "            for char in os.listdir(os.path.join(img_dir, alph_name))\n",
        "      ])\n",
        "\n",
        "\n",
        "y = np.zeros((N), 'int') # ground truth\n",
        "current_character_folder = 0 # carpeta de un caracter visitado\n",
        "\n",
        "df_alphabet_names = []\n",
        "df_character_names = []\n",
        "df_character_idx = []\n",
        "df_paths = []\n",
        "df_y = []\n",
        "\n",
        "for i in range(len(alphabet_names)):\n",
        "  alphabet_name = alphabet_names[i]\n",
        "  character_length = character_lengths[i]\n",
        "  character_folders = sorted(os.listdir(os.path.join(img_dir, alphabet_name)))\n",
        "\n",
        "  for j in range(character_length):\n",
        "    character_folder = character_folders[j]\n",
        "    characters = sorted(os.listdir(os.path.join(img_dir, alphabet_name, character_folder)))\n",
        "    # print(character_folder)\n",
        "\n",
        "    for k in range(nreps):\n",
        "      y[(current_character_folder * nreps) + k] = current_character_folder\n",
        "\n",
        "      # Se añade al Df\n",
        "      df_alphabet_names.extend([alphabet_name])\n",
        "      df_character_names.extend([character_folder])\n",
        "      df_character_idx.extend([k])\n",
        "      df_paths.extend([os.path.join(img_dir, alphabet_name, character_folder, characters[k])])\n",
        "      df_y.extend([current_character_folder])\n",
        "\n",
        "    current_character_folder += 1\n",
        "\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'Alphabet': df_alphabet_names,\n",
        "    'Character': df_character_names,\n",
        "    'Sample': df_character_idx,\n",
        "    'Path': df_paths,\n",
        "    'y': df_y\n",
        "})"
      ],
      "metadata": {
        "id": "F5WwCV9K7T2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al observar las muestras que tenemos, se obtiene lo siguiente"
      ],
      "metadata": {
        "id": "FkpwjLruG6Kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "3nE6_A7cGxpJ",
        "outputId": "63828e7f-7e5e-4357-a6ab-1e77800ebfea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   Alphabet    Character  Sample  \\\n",
              "0      Alphabet_of_the_Magi  character01       0   \n",
              "1      Alphabet_of_the_Magi  character01       1   \n",
              "2      Alphabet_of_the_Magi  character01       2   \n",
              "3      Alphabet_of_the_Magi  character01       3   \n",
              "4      Alphabet_of_the_Magi  character01       4   \n",
              "...                     ...          ...     ...   \n",
              "19275              Tifinagh  character55      15   \n",
              "19276              Tifinagh  character55      16   \n",
              "19277              Tifinagh  character55      17   \n",
              "19278              Tifinagh  character55      18   \n",
              "19279              Tifinagh  character55      19   \n",
              "\n",
              "                                                    Path    y  \n",
              "0      images_background/Alphabet_of_the_Magi/charact...    0  \n",
              "1      images_background/Alphabet_of_the_Magi/charact...    0  \n",
              "2      images_background/Alphabet_of_the_Magi/charact...    0  \n",
              "3      images_background/Alphabet_of_the_Magi/charact...    0  \n",
              "4      images_background/Alphabet_of_the_Magi/charact...    0  \n",
              "...                                                  ...  ...  \n",
              "19275  images_background/Tifinagh/character55/0964_16...  963  \n",
              "19276  images_background/Tifinagh/character55/0964_17...  963  \n",
              "19277  images_background/Tifinagh/character55/0964_18...  963  \n",
              "19278  images_background/Tifinagh/character55/0964_19...  963  \n",
              "19279  images_background/Tifinagh/character55/0964_20...  963  \n",
              "\n",
              "[19280 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d57fac20-83bc-4421-a82f-12f99961994c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Alphabet</th>\n",
              "      <th>Character</th>\n",
              "      <th>Sample</th>\n",
              "      <th>Path</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Alphabet_of_the_Magi</td>\n",
              "      <td>character01</td>\n",
              "      <td>0</td>\n",
              "      <td>images_background/Alphabet_of_the_Magi/charact...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Alphabet_of_the_Magi</td>\n",
              "      <td>character01</td>\n",
              "      <td>1</td>\n",
              "      <td>images_background/Alphabet_of_the_Magi/charact...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Alphabet_of_the_Magi</td>\n",
              "      <td>character01</td>\n",
              "      <td>2</td>\n",
              "      <td>images_background/Alphabet_of_the_Magi/charact...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Alphabet_of_the_Magi</td>\n",
              "      <td>character01</td>\n",
              "      <td>3</td>\n",
              "      <td>images_background/Alphabet_of_the_Magi/charact...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Alphabet_of_the_Magi</td>\n",
              "      <td>character01</td>\n",
              "      <td>4</td>\n",
              "      <td>images_background/Alphabet_of_the_Magi/charact...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19275</th>\n",
              "      <td>Tifinagh</td>\n",
              "      <td>character55</td>\n",
              "      <td>15</td>\n",
              "      <td>images_background/Tifinagh/character55/0964_16...</td>\n",
              "      <td>963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19276</th>\n",
              "      <td>Tifinagh</td>\n",
              "      <td>character55</td>\n",
              "      <td>16</td>\n",
              "      <td>images_background/Tifinagh/character55/0964_17...</td>\n",
              "      <td>963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19277</th>\n",
              "      <td>Tifinagh</td>\n",
              "      <td>character55</td>\n",
              "      <td>17</td>\n",
              "      <td>images_background/Tifinagh/character55/0964_18...</td>\n",
              "      <td>963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19278</th>\n",
              "      <td>Tifinagh</td>\n",
              "      <td>character55</td>\n",
              "      <td>18</td>\n",
              "      <td>images_background/Tifinagh/character55/0964_19...</td>\n",
              "      <td>963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19279</th>\n",
              "      <td>Tifinagh</td>\n",
              "      <td>character55</td>\n",
              "      <td>19</td>\n",
              "      <td>images_background/Tifinagh/character55/0964_20...</td>\n",
              "      <td>963</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19280 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d57fac20-83bc-4421-a82f-12f99961994c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d57fac20-83bc-4421-a82f-12f99961994c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d57fac20-83bc-4421-a82f-12f99961994c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo de una imagen"
      ],
      "metadata": {
        "id": "5EVtbenEOMcj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = df.iloc[0]['Path']\n",
        "img = Image.open(path)\n",
        "# print('Shape:', img.shape)\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "EHSDlVH9OOBw",
        "outputId": "b0ed5903-b292-431f-ff62-16248100e67a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyTyPtfIBV9J",
        "outputId": "436b66d8-2a64-4a2d-b493-0e5f8fb066da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PIL.PngImagePlugin.PngImageFile image mode=1 size=105x105 at 0x7F61F9D5EE30>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Separación Train - Val - Test:\n",
        "\n",
        "El objetivo de la ResNet es justamente clasificar cada uno de los caracteres. En total, tenemos 964 caracteres distintos (labels enumerados del 0 al 963), provenientes de 30 alfabetos, y cada caracter posee 20 muestras. Por ende, tenemos 19280 imagenes distintas.\n",
        "\n",
        "Dado que cada caracter posee 20 muestras, se utilizará una proporción 70% train, 20% validation y 10% test. Vale decir: 14 imágenes de train, 4 de validation, y 2 de test por cada caracter.\n",
        "\n",
        "En total debería dar:\n",
        "* 13.496 imágenes de Train\n",
        "* 3.856 imágenes de Validation\n",
        "* 1.928 imágenes de Test"
      ],
      "metadata": {
        "id": "E-yYhKZmD9PF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separacion de df basados en el numero de fila\n",
        "df_train = df.groupby('y').head(14)\n",
        "df_val = df.groupby('y').apply(lambda x: x.iloc[14:18])\n",
        "df_test = df.groupby('y').apply(lambda x: x.iloc[18:20])\n",
        "\n",
        "# Reseteamos los indices de los df\n",
        "df_train.reset_index(drop=True, inplace=True)\n",
        "df_val.reset_index(drop=True, inplace=True)\n",
        "df_test.reset_index(drop=True, inplace=True)\n"
      ],
      "metadata": {
        "id": "HIL7mN16PIVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Length df_train:', len(df_train))\n",
        "print('Length df_val:', len(df_val))\n",
        "print('Length df_test:', len(df_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scalaQkmQuY_",
        "outputId": "6e02bafe-9bdb-4642-a72e-eab990605f1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length df_train: 13496\n",
            "Length df_val: 3856\n",
            "Length df_test: 1928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por ejemplo, si vemos como quedó el df_train:"
      ],
      "metadata": {
        "id": "OCVt-njlQ23W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train[0:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "dwzHy4OLRCmM",
        "outputId": "c66646f1-c896-4767-96fb-03ccfde2ab44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Alphabet    Character  Sample  \\\n",
              "0   Alphabet_of_the_Magi  character01       0   \n",
              "1   Alphabet_of_the_Magi  character01       1   \n",
              "2   Alphabet_of_the_Magi  character01       2   \n",
              "3   Alphabet_of_the_Magi  character01       3   \n",
              "4   Alphabet_of_the_Magi  character01       4   \n",
              "5   Alphabet_of_the_Magi  character01       5   \n",
              "6   Alphabet_of_the_Magi  character01       6   \n",
              "7   Alphabet_of_the_Magi  character01       7   \n",
              "8   Alphabet_of_the_Magi  character01       8   \n",
              "9   Alphabet_of_the_Magi  character01       9   \n",
              "10  Alphabet_of_the_Magi  character01      10   \n",
              "11  Alphabet_of_the_Magi  character01      11   \n",
              "12  Alphabet_of_the_Magi  character01      12   \n",
              "13  Alphabet_of_the_Magi  character01      13   \n",
              "14  Alphabet_of_the_Magi  character02       0   \n",
              "15  Alphabet_of_the_Magi  character02       1   \n",
              "16  Alphabet_of_the_Magi  character02       2   \n",
              "17  Alphabet_of_the_Magi  character02       3   \n",
              "18  Alphabet_of_the_Magi  character02       4   \n",
              "19  Alphabet_of_the_Magi  character02       5   \n",
              "\n",
              "                                                 Path  y  \n",
              "0   images_background/Alphabet_of_the_Magi/charact...  0  \n",
              "1   images_background/Alphabet_of_the_Magi/charact...  0  \n",
              "2   images_background/Alphabet_of_the_Magi/charact...  0  \n",
              "3   images_background/Alphabet_of_the_Magi/charact...  0  \n",
              "4   images_background/Alphabet_of_the_Magi/charact...  0  \n",
              "5   images_background/Alphabet_of_the_Magi/charact...  0  \n",
              "6   images_background/Alphabet_of_the_Magi/charact...  0  \n",
              "7   images_background/Alphabet_of_the_Magi/charact...  0  \n",
              "8   images_background/Alphabet_of_the_Magi/charact...  0  \n",
              "9   images_background/Alphabet_of_the_Magi/charact...  0  \n",
              "10  images_background/Alphabet_of_the_Magi/charact...  0  \n",
              "11  images_background/Alphabet_of_the_Magi/charact...  0  \n",
              "12  images_background/Alphabet_of_the_Magi/charact...  0  \n",
              "13  images_background/Alphabet_of_the_Magi/charact...  0  \n",
              "14  images_background/Alphabet_of_the_Magi/charact...  1  \n",
              "15  images_background/Alphabet_of_the_Magi/charact...  1  \n",
              "16  images_background/Alphabet_of_the_Magi/charact...  1  \n",
              "17  images_background/Alphabet_of_the_Magi/charact...  1  \n",
              "18  images_background/Alphabet_of_the_Magi/charact...  1  \n",
              "19  images_background/Alphabet_of_the_Magi/charact...  1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa1a5de5-1152-425f-b0fd-203ef4466208\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Alphabet</th>\n",
              "      <th>Character</th>\n",
              "      <th>Sample</th>\n",
              "      <th>Path</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Alphabet_of_the_Magi</td>\n",
              "      <td>character01</td>\n",
              "      <td>0</td>\n",
              "      <td>images_background/Alphabet_of_the_Magi/charact...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Alphabet_of_the_Magi</td>\n",
              "      <td>character01</td>\n",
              "      <td>1</td>\n",
              "      <td>images_background/Alphabet_of_the_Magi/charact...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Alphabet_of_the_Magi</td>\n",
              "      <td>character01</td>\n",
              "      <td>2</td>\n",
              "      <td>images_background/Alphabet_of_the_Magi/charact...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Alphabet_of_the_Magi</td>\n",
              "      <td>character01</td>\n",
              "      <td>3</td>\n",
              "      <td>images_background/Alphabet_of_the_Magi/charact...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Alphabet_of_the_Magi</td>\n",
              "      <td>character01</td>\n",
              "      <td>4</td>\n",
              "      <td>images_background/Alphabet_of_the_Magi/charact...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Alphabet_of_the_Magi</td>\n",
              "      <td>character01</td>\n",
              "      <td>5</td>\n",
              "      <td>images_background/Alphabet_of_the_Magi/charact...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Alphabet_of_the_Magi</td>\n",
              "      <td>character01</td>\n",
              "      <td>6</td>\n",
              "      <td>images_background/Alphabet_of_the_Magi/charact...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Alphabet_of_the_Magi</td>\n",
              "      <td>character01</td>\n",
              "      <td>7</td>\n",
              "      <td>images_background/Alphabet_of_the_Magi/charact...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Alphabet_of_the_Magi</td>\n",
              "      <td>character01</td>\n",
              "      <td>8</td>\n",
              "      <td>images_background/Alphabet_of_the_Magi/charact...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Alphabet_of_the_Magi</td>\n",
              "      <td>character01</td>\n",
              "      <td>9</td>\n",
              "      <td>images_background/Alphabet_of_the_Magi/charact...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Alphabet_of_the_Magi</td>\n",
              "      <td>character01</td>\n",
              "      <td>10</td>\n",
              "      <td>images_background/Alphabet_of_the_Magi/charact...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Alphabet_of_the_Magi</td>\n",
              "      <td>character01</td>\n",
              "      <td>11</td>\n",
              "      <td>images_background/Alphabet_of_the_Magi/charact...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Alphabet_of_the_Magi</td>\n",
              "      <td>character01</td>\n",
              "      <td>12</td>\n",
              "      <td>images_background/Alphabet_of_the_Magi/charact...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Alphabet_of_the_Magi</td>\n",
              "      <td>character01</td>\n",
              "      <td>13</td>\n",
              "      <td>images_background/Alphabet_of_the_Magi/charact...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Alphabet_of_the_Magi</td>\n",
              "      <td>character02</td>\n",
              "      <td>0</td>\n",
              "      <td>images_background/Alphabet_of_the_Magi/charact...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Alphabet_of_the_Magi</td>\n",
              "      <td>character02</td>\n",
              "      <td>1</td>\n",
              "      <td>images_background/Alphabet_of_the_Magi/charact...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Alphabet_of_the_Magi</td>\n",
              "      <td>character02</td>\n",
              "      <td>2</td>\n",
              "      <td>images_background/Alphabet_of_the_Magi/charact...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Alphabet_of_the_Magi</td>\n",
              "      <td>character02</td>\n",
              "      <td>3</td>\n",
              "      <td>images_background/Alphabet_of_the_Magi/charact...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Alphabet_of_the_Magi</td>\n",
              "      <td>character02</td>\n",
              "      <td>4</td>\n",
              "      <td>images_background/Alphabet_of_the_Magi/charact...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Alphabet_of_the_Magi</td>\n",
              "      <td>character02</td>\n",
              "      <td>5</td>\n",
              "      <td>images_background/Alphabet_of_the_Magi/charact...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa1a5de5-1152-425f-b0fd-203ef4466208')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fa1a5de5-1152-425f-b0fd-203ef4466208 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fa1a5de5-1152-425f-b0fd-203ef4466208');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo ResNeXt"
      ],
      "metadata": {
        "id": "SzIGGLV0Juuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 964 # Cantidad de clases que hay"
      ],
      "metadata": {
        "id": "9EjltURwMuNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnext101_64x4d(weights=ResNeXt101_64X4D_Weights.IMAGENET1K_V1)\n",
        "model.fc = nn.Linear(2048, num_classes, bias=True)\n",
        "model.aux_logits=False\n",
        "model.to(device)\n",
        "\n",
        "for param in model.parameters(): param.requires_grad = False\n",
        "\n",
        "# Descongelamos la última capa\n",
        "for param in model.fc.parameters(): param.requires_grad = True\n",
        "\n",
        "summary(model, input_size=(3, 105, 105))\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.7)"
      ],
      "metadata": {
        "id": "3jMXEvmeM79Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da693324-b4c3-4e95-dcc7-540e61556b78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnext101_64x4d-173b62eb.pth\" to /root/.cache/torch/hub/checkpoints/resnext101_64x4d-173b62eb.pth\n",
            "100%|██████████| 319M/319M [00:05<00:00, 61.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 53, 53]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 53, 53]             128\n",
            "              ReLU-3           [-1, 64, 53, 53]               0\n",
            "         MaxPool2d-4           [-1, 64, 27, 27]               0\n",
            "            Conv2d-5          [-1, 256, 27, 27]          16,384\n",
            "       BatchNorm2d-6          [-1, 256, 27, 27]             512\n",
            "              ReLU-7          [-1, 256, 27, 27]               0\n",
            "            Conv2d-8          [-1, 256, 27, 27]           9,216\n",
            "       BatchNorm2d-9          [-1, 256, 27, 27]             512\n",
            "             ReLU-10          [-1, 256, 27, 27]               0\n",
            "           Conv2d-11          [-1, 256, 27, 27]          65,536\n",
            "      BatchNorm2d-12          [-1, 256, 27, 27]             512\n",
            "           Conv2d-13          [-1, 256, 27, 27]          16,384\n",
            "      BatchNorm2d-14          [-1, 256, 27, 27]             512\n",
            "             ReLU-15          [-1, 256, 27, 27]               0\n",
            "       Bottleneck-16          [-1, 256, 27, 27]               0\n",
            "           Conv2d-17          [-1, 256, 27, 27]          65,536\n",
            "      BatchNorm2d-18          [-1, 256, 27, 27]             512\n",
            "             ReLU-19          [-1, 256, 27, 27]               0\n",
            "           Conv2d-20          [-1, 256, 27, 27]           9,216\n",
            "      BatchNorm2d-21          [-1, 256, 27, 27]             512\n",
            "             ReLU-22          [-1, 256, 27, 27]               0\n",
            "           Conv2d-23          [-1, 256, 27, 27]          65,536\n",
            "      BatchNorm2d-24          [-1, 256, 27, 27]             512\n",
            "             ReLU-25          [-1, 256, 27, 27]               0\n",
            "       Bottleneck-26          [-1, 256, 27, 27]               0\n",
            "           Conv2d-27          [-1, 256, 27, 27]          65,536\n",
            "      BatchNorm2d-28          [-1, 256, 27, 27]             512\n",
            "             ReLU-29          [-1, 256, 27, 27]               0\n",
            "           Conv2d-30          [-1, 256, 27, 27]           9,216\n",
            "      BatchNorm2d-31          [-1, 256, 27, 27]             512\n",
            "             ReLU-32          [-1, 256, 27, 27]               0\n",
            "           Conv2d-33          [-1, 256, 27, 27]          65,536\n",
            "      BatchNorm2d-34          [-1, 256, 27, 27]             512\n",
            "             ReLU-35          [-1, 256, 27, 27]               0\n",
            "       Bottleneck-36          [-1, 256, 27, 27]               0\n",
            "           Conv2d-37          [-1, 512, 27, 27]         131,072\n",
            "      BatchNorm2d-38          [-1, 512, 27, 27]           1,024\n",
            "             ReLU-39          [-1, 512, 27, 27]               0\n",
            "           Conv2d-40          [-1, 512, 14, 14]          36,864\n",
            "      BatchNorm2d-41          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-42          [-1, 512, 14, 14]               0\n",
            "           Conv2d-43          [-1, 512, 14, 14]         262,144\n",
            "      BatchNorm2d-44          [-1, 512, 14, 14]           1,024\n",
            "           Conv2d-45          [-1, 512, 14, 14]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-47          [-1, 512, 14, 14]               0\n",
            "       Bottleneck-48          [-1, 512, 14, 14]               0\n",
            "           Conv2d-49          [-1, 512, 14, 14]         262,144\n",
            "      BatchNorm2d-50          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-51          [-1, 512, 14, 14]               0\n",
            "           Conv2d-52          [-1, 512, 14, 14]          36,864\n",
            "      BatchNorm2d-53          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-54          [-1, 512, 14, 14]               0\n",
            "           Conv2d-55          [-1, 512, 14, 14]         262,144\n",
            "      BatchNorm2d-56          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-57          [-1, 512, 14, 14]               0\n",
            "       Bottleneck-58          [-1, 512, 14, 14]               0\n",
            "           Conv2d-59          [-1, 512, 14, 14]         262,144\n",
            "      BatchNorm2d-60          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-61          [-1, 512, 14, 14]               0\n",
            "           Conv2d-62          [-1, 512, 14, 14]          36,864\n",
            "      BatchNorm2d-63          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-64          [-1, 512, 14, 14]               0\n",
            "           Conv2d-65          [-1, 512, 14, 14]         262,144\n",
            "      BatchNorm2d-66          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-67          [-1, 512, 14, 14]               0\n",
            "       Bottleneck-68          [-1, 512, 14, 14]               0\n",
            "           Conv2d-69          [-1, 512, 14, 14]         262,144\n",
            "      BatchNorm2d-70          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-71          [-1, 512, 14, 14]               0\n",
            "           Conv2d-72          [-1, 512, 14, 14]          36,864\n",
            "      BatchNorm2d-73          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-74          [-1, 512, 14, 14]               0\n",
            "           Conv2d-75          [-1, 512, 14, 14]         262,144\n",
            "      BatchNorm2d-76          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-77          [-1, 512, 14, 14]               0\n",
            "       Bottleneck-78          [-1, 512, 14, 14]               0\n",
            "           Conv2d-79         [-1, 1024, 14, 14]         524,288\n",
            "      BatchNorm2d-80         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-81         [-1, 1024, 14, 14]               0\n",
            "           Conv2d-82           [-1, 1024, 7, 7]         147,456\n",
            "      BatchNorm2d-83           [-1, 1024, 7, 7]           2,048\n",
            "             ReLU-84           [-1, 1024, 7, 7]               0\n",
            "           Conv2d-85           [-1, 1024, 7, 7]       1,048,576\n",
            "      BatchNorm2d-86           [-1, 1024, 7, 7]           2,048\n",
            "           Conv2d-87           [-1, 1024, 7, 7]         524,288\n",
            "      BatchNorm2d-88           [-1, 1024, 7, 7]           2,048\n",
            "             ReLU-89           [-1, 1024, 7, 7]               0\n",
            "       Bottleneck-90           [-1, 1024, 7, 7]               0\n",
            "           Conv2d-91           [-1, 1024, 7, 7]       1,048,576\n",
            "      BatchNorm2d-92           [-1, 1024, 7, 7]           2,048\n",
            "             ReLU-93           [-1, 1024, 7, 7]               0\n",
            "           Conv2d-94           [-1, 1024, 7, 7]         147,456\n",
            "      BatchNorm2d-95           [-1, 1024, 7, 7]           2,048\n",
            "             ReLU-96           [-1, 1024, 7, 7]               0\n",
            "           Conv2d-97           [-1, 1024, 7, 7]       1,048,576\n",
            "      BatchNorm2d-98           [-1, 1024, 7, 7]           2,048\n",
            "             ReLU-99           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-100           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-101           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-102           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-103           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-104           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-105           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-106           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-107           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-108           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-109           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-110           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-111           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-112           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-113           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-114           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-115           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-116           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-117           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-118           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-119           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-120           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-121           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-122           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-123           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-124           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-125           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-126           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-127           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-128           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-129           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-130           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-131           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-132           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-133           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-134           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-135           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-136           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-137           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-138           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-139           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-140           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-141           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-142           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-143           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-144           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-145           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-146           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-147           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-148           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-149           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-150           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-151           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-152           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-153           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-154           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-155           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-156           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-157           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-158           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-159           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-160           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-161           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-162           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-163           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-164           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-165           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-166           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-167           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-168           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-169           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-170           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-171           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-172           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-173           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-174           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-175           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-176           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-177           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-178           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-179           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-180           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-181           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-182           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-183           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-184           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-185           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-186           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-187           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-188           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-189           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-190           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-191           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-192           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-193           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-194           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-195           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-196           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-197           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-198           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-199           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-200           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-201           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-202           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-203           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-204           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-205           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-206           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-207           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-208           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-209           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-210           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-211           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-212           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-213           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-214           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-215           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-216           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-217           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-218           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-219           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-220           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-221           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-222           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-223           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-224           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-225           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-226           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-227           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-228           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-229           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-230           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-231           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-232           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-233           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-234           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-235           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-236           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-237           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-238           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-239           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-240           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-241           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-242           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-243           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-244           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-245           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-246           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-247           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-248           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-249           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-250           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-251           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-252           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-253           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-254           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-255           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-256           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-257           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-258           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-259           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-260           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-261           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-262           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-263           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-264           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-265           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-266           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-267           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-268           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-269           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-270           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-271           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-272           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-273           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-274           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-275           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-276           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-277           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-278           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-279           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-280           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-281           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-282           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-283           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-284           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-285           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-286           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-287           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-288           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-289           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-290           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-291           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-292           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-293           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-294           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-295           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-296           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-297           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-298           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-299           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-300           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-301           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-302           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-303           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-304           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-305           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-306           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-307           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-308           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-309           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-310           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-311           [-1, 2048, 7, 7]       2,097,152\n",
            "     BatchNorm2d-312           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-313           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-314           [-1, 2048, 4, 4]         589,824\n",
            "     BatchNorm2d-315           [-1, 2048, 4, 4]           4,096\n",
            "            ReLU-316           [-1, 2048, 4, 4]               0\n",
            "          Conv2d-317           [-1, 2048, 4, 4]       4,194,304\n",
            "     BatchNorm2d-318           [-1, 2048, 4, 4]           4,096\n",
            "          Conv2d-319           [-1, 2048, 4, 4]       2,097,152\n",
            "     BatchNorm2d-320           [-1, 2048, 4, 4]           4,096\n",
            "            ReLU-321           [-1, 2048, 4, 4]               0\n",
            "      Bottleneck-322           [-1, 2048, 4, 4]               0\n",
            "          Conv2d-323           [-1, 2048, 4, 4]       4,194,304\n",
            "     BatchNorm2d-324           [-1, 2048, 4, 4]           4,096\n",
            "            ReLU-325           [-1, 2048, 4, 4]               0\n",
            "          Conv2d-326           [-1, 2048, 4, 4]         589,824\n",
            "     BatchNorm2d-327           [-1, 2048, 4, 4]           4,096\n",
            "            ReLU-328           [-1, 2048, 4, 4]               0\n",
            "          Conv2d-329           [-1, 2048, 4, 4]       4,194,304\n",
            "     BatchNorm2d-330           [-1, 2048, 4, 4]           4,096\n",
            "            ReLU-331           [-1, 2048, 4, 4]               0\n",
            "      Bottleneck-332           [-1, 2048, 4, 4]               0\n",
            "          Conv2d-333           [-1, 2048, 4, 4]       4,194,304\n",
            "     BatchNorm2d-334           [-1, 2048, 4, 4]           4,096\n",
            "            ReLU-335           [-1, 2048, 4, 4]               0\n",
            "          Conv2d-336           [-1, 2048, 4, 4]         589,824\n",
            "     BatchNorm2d-337           [-1, 2048, 4, 4]           4,096\n",
            "            ReLU-338           [-1, 2048, 4, 4]               0\n",
            "          Conv2d-339           [-1, 2048, 4, 4]       4,194,304\n",
            "     BatchNorm2d-340           [-1, 2048, 4, 4]           4,096\n",
            "            ReLU-341           [-1, 2048, 4, 4]               0\n",
            "      Bottleneck-342           [-1, 2048, 4, 4]               0\n",
            "AdaptiveAvgPool2d-343           [-1, 2048, 1, 1]               0\n",
            "          Linear-344                  [-1, 964]       1,975,236\n",
            "================================================================\n",
            "Total params: 83,381,508\n",
            "Trainable params: 1,975,236\n",
            "Non-trainable params: 81,406,272\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.13\n",
            "Forward/backward pass size (MB): 190.26\n",
            "Params size (MB): 318.08\n",
            "Estimated Total Size (MB): 508.46\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "fnBVH6wfNSjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Character(torch.utils.data.Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.transform = transform\n",
        "        self.images = images     # Vincula el indice con un nombre de archivo\n",
        "        self.labels = labels     # Vincula el indice con una clase\n",
        "\n",
        "    def get_image(self, path):\n",
        "        # img = plt.imread(path)\n",
        "        img = Image.open(path)\n",
        "        return img\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path_name = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        img = self.get_image(path_name)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)"
      ],
      "metadata": {
        "id": "_u5gUIleQqAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up data transformations\n",
        "transform = Compose([\n",
        "    lambda x: x.convert('RGB'),\n",
        "    ToTensor(),\n",
        "    Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "\n",
        "train_dataset = Character(images=df_train['Path'], labels=df_train['y'], transform=transform)\n",
        "val_dataset = Character(images=df_val['Path'], labels=df_val['y'], transform=transform)\n",
        "test_dataset = Character(images=df_test['Path'], labels=df_test['y'], transform=transform)"
      ],
      "metadata": {
        "id": "RLglVdEkRAhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train Dataset Length:', len(train_dataset))\n",
        "print('Val Dataset Length:', len(val_dataset))\n",
        "print('Test Dataset Length:', len(test_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yRb4EGGS4rc",
        "outputId": "e1fb9f9f-ef6b-466d-8240-b92ecbd58979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset Length: 13496\n",
            "Val Dataset Length: 3856\n",
            "Test Dataset Length: 1928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the train loader\n",
        "batch_size = 64\n",
        "shuffle = True\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle)"
      ],
      "metadata": {
        "id": "8bpcoym0QH7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainiter = iter(train_loader)\n",
        "features, labels = next(trainiter)\n",
        "print(features.shape, labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_O7F4P4F_iH",
        "outputId": "661addbb-4294-455c-b722-5da19a31dbcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 105, 105]) torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uvzXDbJTP6c",
        "outputId": "c1f1170a-2c53-4701-b9fc-577362dcc176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "211"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('models', exist_ok=True)\n",
        "model_path = 'models/ResNeXt'\n"
      ],
      "metadata": {
        "id": "fONePAmkJny0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "-ocu1pr5Ln7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para correr inferencia usando un modelo y un\n",
        "# DataLoader con nuestros datos del set de test.\n",
        "def test_model(model, test_dl):\n",
        "    total_correctas = 0.0\n",
        "    total_muestras = 0.0\n",
        "\n",
        "    for x, target in test_dl:          # Iteramos sobre nuestros datos\n",
        "        # Inicio de la iteración\n",
        "        model.eval()                        # Dejamos el modelo en modo evaluación\n",
        "        with torch.no_grad():               # No se calculará información de gradientes\n",
        "                                            # en el código de más abajo.\n",
        "            x = x.cuda()\n",
        "            target = target.cuda()          # Enviamos nuestros datos a GPU\n",
        "            output = model(x)               # Hacemos el forward de nuestros datos\n",
        "\n",
        "            preds = output.argmax(dim=1)             # El máximo valor es nuestra predicción\n",
        "            correctas = (preds == target).sum()      # Acumulamos las correctas durante la época\n",
        "            total_correctas += correctas\n",
        "            total_muestras += target.shape[0]        # Sumamos el tamaño del batch\n",
        "\n",
        "            accuracy = total_correctas/total_muestras # Acc = correctas/total\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "sfZ9jg9ALnqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnext101_64x4d(weights=ResNeXt101_64X4D_Weights.IMAGENET1K_V1)\n",
        "model.fc = nn.Linear(2048, num_classes, bias=True)\n",
        "model.aux_logits=False\n",
        "model.to(device)\n",
        "\n",
        "for param in model.parameters(): param.requires_grad = False\n",
        "\n",
        "# Descongelamos la última capa\n",
        "for param in model.fc.parameters(): param.requires_grad = True\n",
        "\n",
        "summary(model, input_size=(3, 105, 105))\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "learning_rate = \"6e-3\"\n",
        "l_r = 6e-3\n",
        "opti = \"Adam\"\n",
        "# optimizer = optim.SGD(model.parameters(), lr=l_r, momentum=0.5)\n",
        "optimizer = optim.Adam(model.parameters(), lr=l_r)\n",
        "# optimizer = optim.Adagrad(model.parameters(), lr=0.009, lr_decay=0.0001)\n",
        "# optimizer = optim.ASGD(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSeU4C4zj0zd",
        "outputId": "300fe73a-d890-4304-dc32-6e72b55df146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 53, 53]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 53, 53]             128\n",
            "              ReLU-3           [-1, 64, 53, 53]               0\n",
            "         MaxPool2d-4           [-1, 64, 27, 27]               0\n",
            "            Conv2d-5          [-1, 256, 27, 27]          16,384\n",
            "       BatchNorm2d-6          [-1, 256, 27, 27]             512\n",
            "              ReLU-7          [-1, 256, 27, 27]               0\n",
            "            Conv2d-8          [-1, 256, 27, 27]           9,216\n",
            "       BatchNorm2d-9          [-1, 256, 27, 27]             512\n",
            "             ReLU-10          [-1, 256, 27, 27]               0\n",
            "           Conv2d-11          [-1, 256, 27, 27]          65,536\n",
            "      BatchNorm2d-12          [-1, 256, 27, 27]             512\n",
            "           Conv2d-13          [-1, 256, 27, 27]          16,384\n",
            "      BatchNorm2d-14          [-1, 256, 27, 27]             512\n",
            "             ReLU-15          [-1, 256, 27, 27]               0\n",
            "       Bottleneck-16          [-1, 256, 27, 27]               0\n",
            "           Conv2d-17          [-1, 256, 27, 27]          65,536\n",
            "      BatchNorm2d-18          [-1, 256, 27, 27]             512\n",
            "             ReLU-19          [-1, 256, 27, 27]               0\n",
            "           Conv2d-20          [-1, 256, 27, 27]           9,216\n",
            "      BatchNorm2d-21          [-1, 256, 27, 27]             512\n",
            "             ReLU-22          [-1, 256, 27, 27]               0\n",
            "           Conv2d-23          [-1, 256, 27, 27]          65,536\n",
            "      BatchNorm2d-24          [-1, 256, 27, 27]             512\n",
            "             ReLU-25          [-1, 256, 27, 27]               0\n",
            "       Bottleneck-26          [-1, 256, 27, 27]               0\n",
            "           Conv2d-27          [-1, 256, 27, 27]          65,536\n",
            "      BatchNorm2d-28          [-1, 256, 27, 27]             512\n",
            "             ReLU-29          [-1, 256, 27, 27]               0\n",
            "           Conv2d-30          [-1, 256, 27, 27]           9,216\n",
            "      BatchNorm2d-31          [-1, 256, 27, 27]             512\n",
            "             ReLU-32          [-1, 256, 27, 27]               0\n",
            "           Conv2d-33          [-1, 256, 27, 27]          65,536\n",
            "      BatchNorm2d-34          [-1, 256, 27, 27]             512\n",
            "             ReLU-35          [-1, 256, 27, 27]               0\n",
            "       Bottleneck-36          [-1, 256, 27, 27]               0\n",
            "           Conv2d-37          [-1, 512, 27, 27]         131,072\n",
            "      BatchNorm2d-38          [-1, 512, 27, 27]           1,024\n",
            "             ReLU-39          [-1, 512, 27, 27]               0\n",
            "           Conv2d-40          [-1, 512, 14, 14]          36,864\n",
            "      BatchNorm2d-41          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-42          [-1, 512, 14, 14]               0\n",
            "           Conv2d-43          [-1, 512, 14, 14]         262,144\n",
            "      BatchNorm2d-44          [-1, 512, 14, 14]           1,024\n",
            "           Conv2d-45          [-1, 512, 14, 14]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-47          [-1, 512, 14, 14]               0\n",
            "       Bottleneck-48          [-1, 512, 14, 14]               0\n",
            "           Conv2d-49          [-1, 512, 14, 14]         262,144\n",
            "      BatchNorm2d-50          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-51          [-1, 512, 14, 14]               0\n",
            "           Conv2d-52          [-1, 512, 14, 14]          36,864\n",
            "      BatchNorm2d-53          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-54          [-1, 512, 14, 14]               0\n",
            "           Conv2d-55          [-1, 512, 14, 14]         262,144\n",
            "      BatchNorm2d-56          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-57          [-1, 512, 14, 14]               0\n",
            "       Bottleneck-58          [-1, 512, 14, 14]               0\n",
            "           Conv2d-59          [-1, 512, 14, 14]         262,144\n",
            "      BatchNorm2d-60          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-61          [-1, 512, 14, 14]               0\n",
            "           Conv2d-62          [-1, 512, 14, 14]          36,864\n",
            "      BatchNorm2d-63          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-64          [-1, 512, 14, 14]               0\n",
            "           Conv2d-65          [-1, 512, 14, 14]         262,144\n",
            "      BatchNorm2d-66          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-67          [-1, 512, 14, 14]               0\n",
            "       Bottleneck-68          [-1, 512, 14, 14]               0\n",
            "           Conv2d-69          [-1, 512, 14, 14]         262,144\n",
            "      BatchNorm2d-70          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-71          [-1, 512, 14, 14]               0\n",
            "           Conv2d-72          [-1, 512, 14, 14]          36,864\n",
            "      BatchNorm2d-73          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-74          [-1, 512, 14, 14]               0\n",
            "           Conv2d-75          [-1, 512, 14, 14]         262,144\n",
            "      BatchNorm2d-76          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-77          [-1, 512, 14, 14]               0\n",
            "       Bottleneck-78          [-1, 512, 14, 14]               0\n",
            "           Conv2d-79         [-1, 1024, 14, 14]         524,288\n",
            "      BatchNorm2d-80         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-81         [-1, 1024, 14, 14]               0\n",
            "           Conv2d-82           [-1, 1024, 7, 7]         147,456\n",
            "      BatchNorm2d-83           [-1, 1024, 7, 7]           2,048\n",
            "             ReLU-84           [-1, 1024, 7, 7]               0\n",
            "           Conv2d-85           [-1, 1024, 7, 7]       1,048,576\n",
            "      BatchNorm2d-86           [-1, 1024, 7, 7]           2,048\n",
            "           Conv2d-87           [-1, 1024, 7, 7]         524,288\n",
            "      BatchNorm2d-88           [-1, 1024, 7, 7]           2,048\n",
            "             ReLU-89           [-1, 1024, 7, 7]               0\n",
            "       Bottleneck-90           [-1, 1024, 7, 7]               0\n",
            "           Conv2d-91           [-1, 1024, 7, 7]       1,048,576\n",
            "      BatchNorm2d-92           [-1, 1024, 7, 7]           2,048\n",
            "             ReLU-93           [-1, 1024, 7, 7]               0\n",
            "           Conv2d-94           [-1, 1024, 7, 7]         147,456\n",
            "      BatchNorm2d-95           [-1, 1024, 7, 7]           2,048\n",
            "             ReLU-96           [-1, 1024, 7, 7]               0\n",
            "           Conv2d-97           [-1, 1024, 7, 7]       1,048,576\n",
            "      BatchNorm2d-98           [-1, 1024, 7, 7]           2,048\n",
            "             ReLU-99           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-100           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-101           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-102           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-103           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-104           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-105           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-106           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-107           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-108           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-109           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-110           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-111           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-112           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-113           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-114           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-115           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-116           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-117           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-118           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-119           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-120           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-121           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-122           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-123           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-124           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-125           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-126           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-127           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-128           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-129           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-130           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-131           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-132           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-133           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-134           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-135           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-136           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-137           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-138           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-139           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-140           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-141           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-142           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-143           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-144           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-145           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-146           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-147           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-148           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-149           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-150           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-151           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-152           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-153           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-154           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-155           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-156           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-157           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-158           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-159           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-160           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-161           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-162           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-163           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-164           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-165           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-166           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-167           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-168           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-169           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-170           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-171           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-172           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-173           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-174           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-175           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-176           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-177           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-178           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-179           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-180           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-181           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-182           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-183           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-184           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-185           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-186           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-187           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-188           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-189           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-190           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-191           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-192           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-193           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-194           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-195           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-196           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-197           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-198           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-199           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-200           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-201           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-202           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-203           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-204           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-205           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-206           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-207           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-208           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-209           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-210           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-211           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-212           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-213           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-214           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-215           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-216           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-217           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-218           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-219           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-220           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-221           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-222           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-223           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-224           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-225           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-226           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-227           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-228           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-229           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-230           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-231           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-232           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-233           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-234           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-235           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-236           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-237           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-238           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-239           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-240           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-241           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-242           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-243           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-244           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-245           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-246           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-247           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-248           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-249           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-250           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-251           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-252           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-253           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-254           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-255           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-256           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-257           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-258           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-259           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-260           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-261           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-262           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-263           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-264           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-265           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-266           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-267           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-268           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-269           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-270           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-271           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-272           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-273           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-274           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-275           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-276           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-277           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-278           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-279           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-280           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-281           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-282           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-283           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-284           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-285           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-286           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-287           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-288           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-289           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-290           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-291           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-292           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-293           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-294           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-295           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-296           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-297           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-298           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-299           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-300           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-301           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-302           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-303           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-304           [-1, 1024, 7, 7]         147,456\n",
            "     BatchNorm2d-305           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-306           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-307           [-1, 1024, 7, 7]       1,048,576\n",
            "     BatchNorm2d-308           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-309           [-1, 1024, 7, 7]               0\n",
            "      Bottleneck-310           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-311           [-1, 2048, 7, 7]       2,097,152\n",
            "     BatchNorm2d-312           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-313           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-314           [-1, 2048, 4, 4]         589,824\n",
            "     BatchNorm2d-315           [-1, 2048, 4, 4]           4,096\n",
            "            ReLU-316           [-1, 2048, 4, 4]               0\n",
            "          Conv2d-317           [-1, 2048, 4, 4]       4,194,304\n",
            "     BatchNorm2d-318           [-1, 2048, 4, 4]           4,096\n",
            "          Conv2d-319           [-1, 2048, 4, 4]       2,097,152\n",
            "     BatchNorm2d-320           [-1, 2048, 4, 4]           4,096\n",
            "            ReLU-321           [-1, 2048, 4, 4]               0\n",
            "      Bottleneck-322           [-1, 2048, 4, 4]               0\n",
            "          Conv2d-323           [-1, 2048, 4, 4]       4,194,304\n",
            "     BatchNorm2d-324           [-1, 2048, 4, 4]           4,096\n",
            "            ReLU-325           [-1, 2048, 4, 4]               0\n",
            "          Conv2d-326           [-1, 2048, 4, 4]         589,824\n",
            "     BatchNorm2d-327           [-1, 2048, 4, 4]           4,096\n",
            "            ReLU-328           [-1, 2048, 4, 4]               0\n",
            "          Conv2d-329           [-1, 2048, 4, 4]       4,194,304\n",
            "     BatchNorm2d-330           [-1, 2048, 4, 4]           4,096\n",
            "            ReLU-331           [-1, 2048, 4, 4]               0\n",
            "      Bottleneck-332           [-1, 2048, 4, 4]               0\n",
            "          Conv2d-333           [-1, 2048, 4, 4]       4,194,304\n",
            "     BatchNorm2d-334           [-1, 2048, 4, 4]           4,096\n",
            "            ReLU-335           [-1, 2048, 4, 4]               0\n",
            "          Conv2d-336           [-1, 2048, 4, 4]         589,824\n",
            "     BatchNorm2d-337           [-1, 2048, 4, 4]           4,096\n",
            "            ReLU-338           [-1, 2048, 4, 4]               0\n",
            "          Conv2d-339           [-1, 2048, 4, 4]       4,194,304\n",
            "     BatchNorm2d-340           [-1, 2048, 4, 4]           4,096\n",
            "            ReLU-341           [-1, 2048, 4, 4]               0\n",
            "      Bottleneck-342           [-1, 2048, 4, 4]               0\n",
            "AdaptiveAvgPool2d-343           [-1, 2048, 1, 1]               0\n",
            "          Linear-344                  [-1, 964]       1,975,236\n",
            "================================================================\n",
            "Total params: 83,381,508\n",
            "Trainable params: 1,975,236\n",
            "Non-trainable params: 81,406,272\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.13\n",
            "Forward/backward pass size (MB): 190.26\n",
            "Params size (MB): 318.08\n",
            "Estimated Total Size (MB): 508.46\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Modelo | Optimizador | Learning Rate | Params | Epoch | Acc Train | Acc Val | Acc Test |\n",
        "| -----  | ----- | ---- | ---- | ---- | ---- | ---- | ---- |\n",
        "| ResNeXt | SGD | 1e-2 | momentum=0.7 | 10 | 0.396 | 0.103 | 0.107 |\n",
        "| ResNeXt | SGD | 5e-3 | momentum=0.9 | 15 | 0.551 | 0.130 | 0.135 |\n",
        "| ResNeXt | SGD | 5e-2 | momentum=0.9 | 10 | 0.961 | 0.186 | 0.204 |\n",
        "| ResNeXt | SGD | 1e-1 | momentum=0.9 | 10 | 0.995 | 0.205 | 0.224 |\n",
        "| ResNeXt | SGD | 1e-0 | momentum=0.9 | 10 | 0.985 | 0.165 | 0.175 |\n",
        "| ResNeXt | SGD | 5e-1 | momentum=0.9 | 10 | 0.995 | 0.194 | 0.222 |\n",
        "| ResNeXt | SGD | 5e-1 | momentum=0.98 | 10 | 0.918 | 0.126 | 0.132 |\n",
        "| ResNeXt | SGD | 5e-1 | momentum=0.5 | 10 | 0.983 | 0.189 | 0.217 |\n",
        "| ResNeXt | Adam | 1e-4 | | 10 | 0.945 | 0.202 | 0.223 |\n",
        "| ResNeXt | Adam | 1e-3 | | 10 | 0.996 | 0.229 | 0.246 |\n",
        "| ResNeXt | Adam | 1e-2 | | 10 | 0.999 | 0.223 | 0.245 |\n",
        "| ResNeXt | Adam | 1e-1 | | 10 | 0.917 | 0.137 | 0.156 |\n",
        "| ResNeXt | Adam | 5e-3 | | 10 | 0.999 | 0.243 | 0.264 |\n",
        "| ResNeXt | Adam | 3e-3 | | 10 | 0.998 | 0.229 | 0.246 |\n",
        "| ResNeXt | Adam | 7e-3 | | 10 | 0.999 | 0.228 | 0.255 |\n",
        "| ResNeXt | Adam | 6e-3 | | 10 | 0.999 | 0.245 | 0.261 |"
      ],
      "metadata": {
        "id": "Nbo_mn5k41PK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Para guardar los valores que queremos visualizar\n",
        "ovrl_history = {\n",
        "    'epochs': [],\n",
        "    'train': {'loss': [], 'acc': []},\n",
        "    'val': {'loss': [], 'acc': []},\n",
        "    'test': {'loss': [], 'acc': []},\n",
        "}\n",
        "\n",
        "n_epochs = 10\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    losses = []\n",
        "    cum_loss = 0.0\n",
        "    cum_acc = 0.0\n",
        "    with tqdm(train_loader, unit='batch', position=0, leave=True) as tepoch:\n",
        "      tepoch.set_description(f\"Epoch {epoch}/{n_epochs}\")\n",
        "      for batch, (data, targets) in enumerate(tepoch, start=1):\n",
        "        optimizer.zero_grad()\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        preds = model(data)\n",
        "        loss = criterion(preds, targets)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, preds = torch.max(preds, dim=1)\n",
        "        cum_acc += torch.sum(preds == targets)\n",
        "\n",
        "        # Cifras de desempeño\n",
        "        cum_loss += loss.item()\n",
        "        curr_loss = cum_loss / batch\n",
        "        curr_acc = cum_acc / (batch * batch_size)\n",
        "        tepoch.set_postfix(Loss=curr_loss, Acc=curr_acc.item())\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    epoch_loss = float(cum_loss / batch)\n",
        "    epoch_acc = float(cum_acc / (batch * batch_size))\n",
        "\n",
        "    # Guardamos la epoca\n",
        "    ovrl_history['epochs'].append(epoch)\n",
        "\n",
        "    # Guardamos el loss y accuracy para la epoca\n",
        "    ovrl_history['train']['loss'].append(epoch_loss)\n",
        "    ovrl_history['train']['acc'].append(epoch_acc)\n",
        "\n",
        "    # Guardamos el loss y accuracy en el set de validacion\n",
        "    val_acc = test_model(model, val_loader)\n",
        "    ovrl_history['val']['loss'].append(epoch_loss)\n",
        "    ovrl_history['val']['acc'].append(float(val_acc))\n",
        "    print(f'Validation Accuracy: {val_acc}')\n",
        "\n",
        "    # Guardamos el loss y accuracy en el set de testing\n",
        "    test_acc = test_model(model, test_loader)\n",
        "    ovrl_history['test']['acc'].append(float(test_acc))\n",
        "    print(f'Testing Accuracy: {test_acc}')\n",
        "\n",
        "    # Guardamos el progreso actual en caso de que se corte la sesión.\n",
        "    # Debe existir el directorio\n",
        "    # Se guarda cada una de las epocas distintas para despues graficarla\n",
        "    torch.save(model, model_path + '_' + str(epoch).zfill(3) + f'_{learning_rate}_{opti}' + '.pt')\n",
        "\n",
        "    print(f'Epoch {epoch + 1} finished\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GsSVKv5KDQi",
        "outputId": "8d5b70f9-ccf5-423b-bc51-10a579995cea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0/10: 100%|██████████| 211/211 [00:51<00:00,  4.06batch/s, Acc=0.141, Loss=5.58]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.17531120777130127\n",
            "Testing Accuracy: 0.1945020854473114\n",
            "Epoch 1 finished\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 211/211 [00:49<00:00,  4.22batch/s, Acc=0.687, Loss=1.51]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.21965768933296204\n",
            "Testing Accuracy: 0.23443984985351562\n",
            "Epoch 2 finished\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 211/211 [00:49<00:00,  4.24batch/s, Acc=0.982, Loss=0.214]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.22691909968852997\n",
            "Testing Accuracy: 0.24533195793628693\n",
            "Epoch 3 finished\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 211/211 [00:49<00:00,  4.25batch/s, Acc=0.998, Loss=0.0726]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.2331431657075882\n",
            "Testing Accuracy: 0.25363072752952576\n",
            "Epoch 4 finished\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 211/211 [00:49<00:00,  4.25batch/s, Acc=0.999, Loss=0.0447]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.23755188286304474\n",
            "Testing Accuracy: 0.25363072752952576\n",
            "Epoch 5 finished\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 211/211 [00:49<00:00,  4.25batch/s, Acc=0.999, Loss=0.0326]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.24170126020908356\n",
            "Testing Accuracy: 0.2572614252567291\n",
            "Epoch 6 finished\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 211/211 [00:49<00:00,  4.26batch/s, Acc=0.999, Loss=0.0201]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.24351660907268524\n",
            "Testing Accuracy: 0.25466805696487427\n",
            "Epoch 7 finished\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 211/211 [00:49<00:00,  4.25batch/s, Acc=0.999, Loss=0.015]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.24455395340919495\n",
            "Testing Accuracy: 0.25933611392974854\n",
            "Epoch 8 finished\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 211/211 [00:49<00:00,  4.26batch/s, Acc=0.999, Loss=0.013]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.24455395340919495\n",
            "Testing Accuracy: 0.259854793548584\n",
            "Epoch 9 finished\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 211/211 [00:49<00:00,  4.25batch/s, Acc=0.999, Loss=0.00969]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.24533195793628693\n",
            "Testing Accuracy: 0.2608921229839325\n",
            "Epoch 10 finished\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ClrqahM1w-nj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}